"""
Filter层提示词模板

包含上下文相关性评分和整理的提示词
"""

# # 上下文相关性评分提示词
# # 用于对候选上下文进行相关性评分和筛选
# CONTEXT_SCORING_PROMPT = """你是一个专业的上下文相关性评估专家，负责评估记忆片段与用户问题的相关性。
# ## 任务说明
# 用户提出了一个问题，系统检索出了一些相关的记忆片段。你需要：
# 1. 为每个记忆片段评估其与用户问题的相关性，给出0.0-1.0的分数
# 2. 移除相关性分数低于0.3的片段
# 3. 按分数从高到低重新排列剩余片段

# ## 评分标准
# - **1.0分**: 完全匹配用户问题，直接包含答案或关键信息
# - **0.8-0.9分**: 高度相关，包含重要的相关信息
# - **0.6-0.7分**: 中等相关，包含部分相关信息
# - **0.4-0.5分**: 低度相关，仅有间接关联
# - **0.1-0.3分**: 几乎无关，应被移除
# - **0.0分**: 完全无关，必须移除

# ## 输出格式
# 你必须以JSON格式返回结果：

# ```json
# {{
#     "scored_contexts": [
#         {{
#             "content": "记忆片段内容",
#             "relevance_score": 0.85,
#             "original_index": 0
#         }},
#         ...
#     ],
#     "summary": "简要说明评分依据"
# }}
# ```

# ## 注意事项
# - 严格按照JSON格式输出
# - 只保留相关性分数≥0.3的片段
# - 按分数降序排列
# - 分数保留2位小数

# 现在开始评估：

# **用户问题**: {user_question}

# **候选记忆片段**:
# {candidate_contexts}

# 请进行相关性评分和筛选："""


# 上下文整理提示词
# 用于将筛选后的上下文整理成连贯的描述
CONTEXT_INTEGRATION_PROMPT = """你是一个专业的信息归纳总结专家，负责将多个余弦相似度相关的记忆片段进行深度整理和归纳。

## 核心任务
将提供的相关记忆片段根据问题的相关性进行智能归纳和提取出与问题相关的内容，对于不相关的内容，直接忽略。输出比原始内容更加精简、逻辑清晰的结果。

## 核心逻辑
1.筛选出有用的记忆片段
2.对筛选出的记忆片段进行归纳和总结
3.如果没有，请返回空字符串

## 处理原则
1. **信息提取**: 识别并提取所有关键信息点
2. **去重合并**: 合并重复或相似的信息，避免冗余
3. **逻辑重构**: 按照时间、类型、重要性等维度重新组织信息
4. **精简表达**: 用更简洁的语言表达相同的含义
5. **结构化输出**: 采用合理的段落结构，提高可读性

## 示例对比
**原始片段（冗余&不相关）**:
"记忆片段1: 余弦相似度是一种衡量两个向量之间夹角余弦值的度量。夹角越小，余弦值越接近1，表示相似度越高。它广泛应用于文本挖掘、推荐系统和图像处理等领域。计算公式是两个向量的点积除以它们各自模的乘积。
记忆片段2: 文本向量化通常使用TF-IDF或Word2Vec。TF-IDF是一种统计方法，用于评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要程度。Word2Vec是一种预测模型，通过训练神经网络来学习词语的分布式表示。
记忆片段3: 余弦相似度的优点是它对向量的长度不敏感，只关注方向。这意味着即使两个文档的长度差异很大，只要它们的主题相似，余弦相似度也能给出高分。
记忆片段4: 在推荐系统中，余弦相似度可以用来计算用户或物品之间的相似度。例如，如果两个用户对相似的电影有高评分，那么他们的余弦相似度会很高。
记忆片段5: 欧氏距离是另一种衡量向量相似度的方法，它计算的是n维空间中两点之间的直线距离。欧氏距离对向量的绝对值大小敏感。
记忆片段6: 余弦相似度在计算时，通常会先对文本进行预处理，比如分词、去除停用词等。然后将文本转换为向量。
记忆片段7: 图像处理中，余弦相似度可以用于比较图像特征向量，例如比较两张图片的颜色直方图相似性。
记忆片段8: 余弦相似度主要用于非负向量，因为负值可能会导致余弦值为负，使得解释复杂。它的取值范围是-1到1。"

**用户问题**: 余弦相似度是什么？它有哪些应用？

**归纳结果（精简&与问题高度相关）**:
"余弦相似度是一种衡量两个向量之间夹角余弦值的度量，其计算公式是两个向量的点积除以它们各自模的乘积。夹角越小，余弦值越接近1，表示相似度越高。余弦相似度的优点在于它对向量的长度不敏感，只关注方向。它广泛应用于文本挖掘、推荐系统和图像处理等领域。具体应用包括：在文本挖掘中比较文本向量的相似性；在推荐系统中计算用户或物品之间的相似度；在图像处理中比较图像特征向量的相似性。"

以下是需要归纳整理的记忆片段：
{filtered_contexts}

请进行深度归纳总结：
"""



# # 获取上下文评分消息
# def get_context_scoring_message(user_question: str, candidate_contexts: list) -> str:
#     """
#     生成上下文评分提示词
    
#     Args:
#         user_question (str): 用户问题
#         candidate_contexts (list): 候选上下文列表
    
#     Returns:
#         str: 格式化的评分提示词
#     """
#     # 格式化候选上下文
#     formatted_contexts = ""
#     for i, context in enumerate(candidate_contexts):
#         formatted_contexts += f"[{i}] {context}\n\n"
    
#     return CONTEXT_SCORING_PROMPT.format(
#         user_question=user_question,
#         candidate_contexts=formatted_contexts.strip()
#     )


# 获取上下文整理消息
def get_context_integration_message(filtered_contexts: list) -> str:
    """
    生成上下文整理提示词
    
    Args:
        filtered_contexts (list): 筛选后的上下文列表
    
    Returns:
        str: 格式化的整理提示词
    """
    # 格式化筛选后的上下文
    formatted_contexts = ""
    for i, context_item in enumerate(filtered_contexts, 1):
        formatted_contexts += f"{i}. {context_item.content}\n\n"
    
    return CONTEXT_INTEGRATION_PROMPT.format(
        filtered_contexts=formatted_contexts.strip()
    ) 